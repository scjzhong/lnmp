1：安装jdk
	A:	linux 下wget http://download.oracle.com/otn-pub/java/jdk/8u162-b12/0da788060d494f5095bf8624735fa2f1/jdk-8u162-linux-x64.tar.gz  
	B:	makdir /usr/local/java  
	C:	mv jdk-8u162-linux-x64.tar.gz /usr/local/java  
	D:	tar -zxvf jdk-8u162-linux-x64.tar.gz  
	E:	vi /etc/profile  
	F: 	在文件的最后写入  
		export JAVA_HOME=/usr/local/java/jdk1.8.0_162  
		xport JRE_HOME=/usr/local/java/jdk1.8.0_162/jre  
		export PATH=$PATH:/usr/local/java/jdk1.8.0_162/bin  
		export CLASSPATH=./:/usr/local/java/jdk1.8.0_162/lib:/usr/local/java/jdk1.8.0_162/jre/lib  
		
	G:	source /etc/profile  
	
	H:	java -version显示如下信息即可  
		java version "1.8.0_162"  
		Java(TM) SE Runtime Environment (build 1.8.0_162-b12)  
		Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)  
		jdk至此安装完毕  

2： 安装mysql
	A:	mv mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz /usr/local/
	B:	cd /usr/local/
	C:  tar -zxvf mysql-5.7.21-linux-glibc2.12-x86_64.tar.gz
	D:  创建mysql用户 
		groupadd mysql
		useradd -r -g mysql -s /bin/false mysql
	E:  创建mysql的数据目录，该目录在初始化数据库的时候会用到 
		mkdir /mysql /mysql/data /mysql/log 
	F:	修改目录权限
		chown -R mysql:mysql /usr/local/mysql /mysql
	G:	创建my.cnf文件
		写入如下内容
			[client]
			port = 3306
			socket = /tmp/mysql.sock
			
			[mysqld]
			server_id=10
			port = 3306
			user = mysql
			character-set-server = utf8mb4
			default_storage_engine = innodb
			log_timestamps = SYSTEM
			socket = /tmp/mysql.sock
			basedir = /usr/local/mysql
			datadir = /mysql/data
			pid-file = /mysql/data/mysql.pid
			max_connections = 1000
			max_connect_errors = 1000
			table_open_cache = 1024
			max_allowed_packet = 128M
			open_files_limit = 65535
			#####====================================[innodb]==============================
			innodb_buffer_pool_size = 1024M
			innodb_file_per_table = 1
			innodb_write_io_threads = 4
			innodb_read_io_threads = 4
			innodb_purge_threads = 2
			innodb_flush_log_at_trx_commit = 1
			innodb_log_file_size = 512M
			innodb_log_files_in_group = 2
			innodb_log_buffer_size = 16M
			innodb_max_dirty_pages_pct = 80
			innodb_lock_wait_timeout = 30
			innodb_data_file_path=ibdata1:1024M:autoextend
			
			#####====================================[log]==============================
			log_error = /mysql/log/mysql-error.log 
			slow_query_log = 1
			long_query_time = 1 
			slow_query_log_file = /mysql/log/mysql-slow.log
			
			sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES
	H:	cd /mysql/log/  touch mysql-error.log
	I:  cd usr/local/mysql/bin
	J:	初始化cd 到bin目录 
			./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/mysql/data  --innodb_undo_tablespaces=3 --explicit_defaults_for_timestamp
		此时在mysql-error.log 会生成一个临时的密码
	K:  修改目录权限  
		chown -R mysql:mysql /usr/local/mysql /mysql
	L:	切换到bin目录下配置启动文件
		cp support-files/mysql.server /etc/init.d/mysql
		
		chkconfig --add mysql
		chkconfig mysql on
		
		service mysql start
		即可启动
	M:	配置环境变量
		vi /etc/profile
		写入如下代码
		mysql_home=/usr/local/mysql
		PATH=$PATH:$mysql_home/bin
		
		source /etc/profile
		
		执行mysql -u root -h localhost -p
		输入mysql-error.log 里的临时的密码
		就ok了。
		
	N:  登录进去之后 需要重新设置密码
		SET PASSWORD=PASSWORD('nihao123');
		即可。
		
	O:  此时本机可以连接到mysql 但是外网还是连接不到
		简单点
		update user set host='%' where user='root';
		flush privileges;
		尝试外网连接
		注意需要关闭
		iptables -F
		关闭selinux	
		然后就可以外网连接了。 
		
3：安装php 
	官网下载镜像 解压
	A:	先安装 依赖
		yum install -y gcc gcc-c++ make cmake bison autoconf wget lrzsz
		yum install -y libtool libtool-ltdl-devel 
		yum install -y freetype-devel libjpeg.x86_64 libjpeg-devel libpng-devel gd-devel
		yum install -y python-devel  patch  sudo 
		yum install -y openssl* openssl openssl-devel ncurses-devel
		yum install -y bzip* bzip2 unzip zlib-devel
		yum install -y libevent*
		yum install -y libxml* libxml2-devel
		yum install -y libcurl* curl-devel 
		yum install -y readline-devel
		yum install -y wget
	B:	
		下载以下库并安装
		tar zxvf /libmcrypt-2.5.8.tar.gz \
		&& cd /libmcrypt-2.5.8 && ./configure && make && make install && cd - / && rm -rf /libmcrypt* \
		&& tar zxvf /mhash-0.9.9.9.tar.gz && cd mhash-0.9.9.9 && ./configure && make && make install && cd - / && rm -rf /mhash* \
		&& tar zxvf /mcrypt-2.6.8.tar.gz && cd mcrypt-2.6.8 && LD_LIBRARY_PATH=/usr/local/lib ./configure && make && make install && cd - / && rm -rf /mcrypt*
	C:	cd 到 解压目录
		./configure --prefix=/usr/local/php --with-config-file-scan-dir=/usr/local/php/etc/ --enable-inline-optimization --enable-opcache --enable-session --enable-fpm --with-mysql=mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --with-pdo-sqlite --with-sqlite3 --with-gettext --enable-mbregex --enable-mbstring --enable-xml --with-iconv --with-mcrypt --with-mhash --with-openssl --enable-bcmath --enable-soap --with-xmlrpc --with-libxml-dir --enable-pcntl --enable-shmop --enable-sysvmsg --enable-sysvsem --enable-sysvshm --enable-sockets --with-curl --with-curlwrappers --with-zlib --enable-zip --with-bz2 --with-gd --enable-gd-native-ttf --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-readline
	D:	make && make install  这个过程有点儿慢
	E:	配置文件
		需要从安装包里复制php.ini、php-fpm.conf到安装目录：
		cd 到解压目录
		cp ./php.ini* /usr/local/php/etc/
		cd /usr/local/php/etc/
		cp php.ini-production php.ini
		cp php-fpm.conf.default  php-fpm.conf
		cp php-fpm.d/www.conf.default php-fpm.d/www.conf
	
	F:  配置php.ini
		# 不显示错误，默认
		display_errors = Off
		
		# 在关闭display_errors后开启PHP错误日志（路径在php-fpm.conf中配置），默认
		log_errors = On
		
		# 字符集，默认
		default_charset = "UTF-8"
		
		# 文件上传大小，默认 
		upload_max_filesize = 2M
		
		# 设置PHP的扩展库路径,，默认被注释了。
		extension_dir = "/usr/local/php7/lib/php/extensions/no-debug-non-zts-20151012/"
		# 如果不设置extension_dir，也可以直接写绝对位置：
		# extension=/usr/local/php/lib/php/extensions/no-debug-non-zts-20151012/redis.so
		
		
		# 设置PHP的时区
		date.timezone = PRC
		
		# 开启opcache，默认是0
		[opcache]
		; Determines if Zend OPCache is enabled
		opcache.enable=1
	
	G:	配置php-fpm.conf
			; 去掉里分号，方便以后重启。建议修改
			; Default Value: none
			; 下面的值最终目录是/usr/local/php/var/run/php-fpm.pid
			; 开启后可以平滑重启php-fpm
			pid = run/php-fpm.pid
			
			; 设置错误日志的路径，可以默认值
			; Note: the default prefix is /usr/local/php/var
			; Default Value: log/php-fpm.log, 即/usr/local/php/var/log/php-fpm.log
			error_log = /var/log/php-fpm/error.log
			
			; Log等级，可以默认值
			; Possible Values: alert, error, warning, notice, debug
			; Default Value: notice
			log_level = notice
			
			; 后台运行，默认yes，可以默认值
			; Default Value: yes
			;daemonize = yes
			
			; 引入www.conf文件中的配置，可以默认值
			include=/usr/local/php/etc/php-fpm.d/*.conf
	H:	配置www.conf（在php-fpm.d目录下）
		
		; 设置用户和用户组，默认都是nobody。可以默认值
		user = nginx
		group = nginx
		
		; 设置PHP监听
		; 下面是默认值，不建议使用。可以默认值
		; listen = 127.0.0.1:9000
		; 根据nginx.conf中的配置fastcgi_pass unix:/var/run/php-fpm/php-fpm.sock;
		listen = /var/run/php-fpm/php-fpm.sock
		
		######开启慢日志。可以默认值
		slowlog = /var/log/php-fpm/$pool-slow.log
		request_slowlog_timeout = 10s
		
		保存配置文件后，检验配置是否正确的方法为:
		/usr/local/php/sbin/php-fpm -t
		如果出现诸如 test is successful 字样，说明配置没有问题。另外该命令也可以让我们知道php-fpm的配置文件在哪。
		
		如若报 [23-Jan-2018 22:09:13] ERROR: failed to open error_log (/var/log/php-fpm/error.log): No such file or directory (2)
		创建改文件即可
		
	
	I:  建立软连接：
		ln -sf /usr/local/php/sbin/php-fpm /usr/bin/
		ln -sf /usr/local/php/bin/php /usr/bin/
		ln -sf /usr/local/php/bin/phpize /usr/bin/
		ln -sf /usr/local/php/bin/php-config /usr/bin/
		ln -sf /usr/local/php/bin/php-cig /usr/bin/
			
	
	J:	启动php-fpm
		 /usr/local/php/sbin/php-fpm 
		 可能会报错 
		[23-Jan-2018 22:13:41] ERROR: [pool www] cannot get uid for user 'nginx'
		[23-Jan-2018 22:13:41] ERROR: FPM initialization failed
		
		执行useradd nginx
		
		 可能会报错 
		[23-Jan-2018 22:14:40] ERROR: unable to bind listening socket for address '/var/run/php-fpm/php-fpm.sock': No such file or directory (2)
		[23-Jan-2018 22:14:40] ERROR: FPM initialization failed
		
		执行touch /var/run/php-fpm/php-fpm.sock
		
		然后启动成功
		
		php-fpm操作汇总：

		/usr/local/php/sbin/php-fpm 		# php-fpm启动
		kill -INT `cat /usr/local/php/var/run/php-fpm.pid` 		# php-fpm关闭
		kill -USR2 `cat /usr/local/php/var/run/php-fpm.pid` 		#php-fpm平滑重启

		 
		 如若出现502  注意先将user group 改为默认 nobody   （可能是权限问题）
		
		/usr/local/php/etc/php-fpm.d
		php-fpm.conf 
		 
		listen.owner = nobody
		listen.group = nobody
		 
		listen = 127.0.0.1:9000	
	
	
	
	
	
4：安装nginx
	官网下载 nginx
	解压 cd 到 源码目录
	
	# 为了支持rewrite功能，我们需要安装pcre
	yum install pcre-devel
	
	# 需要ssl的支持，如果不需要ssl支持，请跳过这一步
	# yum install openssl*
	
	# gzip 类库安装，按需安装
	# yum install zlib zlib-devel
	
	./configure --prefix=/usr/local/nginx --with-http_stub_status_module  --with-http_ssl_module --with-http_realip_module --with-http_sub_module --with-http_gzip_static_module --with-pcre
	
	编译安装nginx	
	make && make install
	
	设置软连接：
	ln -sf /usr/local/nginx/sbin/nginx /usr/sbin 
	
	检测nginx:
	nginx -t
	显示： nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful
	
	

5：	安装node 
		wget https://nodejs.org/dist/v8.5.0/node-v8.5.0-linux-x64.tar.gz
		解压
		mv node-v8.5.0/ /usr/local
		cd node-v8.5.0
		ln /usr/local/node-v8.5.0/bin/node /usr/sbin/ 设置软连接

6：elasticsearch安装
		wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.2.tar.gz
		mv elasticsearch-6.1.2.tar.gz /usr/local/
		tar -zxvf elasticsearch-6.1.2.tar.gz
		cd elasticsearch-6.1.2
		cd bin
		执行启动可能会报错
		./elasticsearch
		报错如下
		
		[2018-01-24T21:07:17,532][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]
		org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root
			at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:125) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:112) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:85) ~[elasticsearch-6.1.2.jar:6.1.2]
		Caused by: java.lang.RuntimeException: can not run elasticsearch as root
			at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:104) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:171) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:322) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:121) ~[elasticsearch-6.1.2.jar:6.1.2]
			... 6 more
			
			
		注意这个报错  org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root
		elasticsearch 不能以root 用户运行。也是为了安全考虑
		
		因为安全问题elasticsearch 不让用root用户直接运行，所以要创建新用户
	
		建议创建一个单独的用户用来运行ElasticSearch
		
		
	A:	创建elsearch用户组及elsearch用户
		groupadd elsearch
		useradd elsearch -g elsearch -p elasticsearch
	
	B:	更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch
		cd /usr/local
		chown -R elsearch:elsearch  elasticsearch-6.1.2
		
	C:	切换到elsearch用户再启动
		su elsearch
		cd /elasticsearch-6.1.2/bin
		启动
		./elasticsearch
		
		
		[2018-01-24T21:28:55,847][INFO ][o.e.n.Node               ] [lHDvvtq] starting ...
		[2018-01-24T21:28:56,311][INFO ][o.e.t.TransportService   ] [lHDvvtq] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
		[2018-01-24T21:28:56,496][WARN ][o.e.b.BootstrapChecks    ] [lHDvvtq] max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
		[2018-01-24T21:28:56,496][WARN ][o.e.b.BootstrapChecks    ] [lHDvvtq] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		[2018-01-24T21:28:59,805][INFO ][o.e.c.s.MasterService    ] [lHDvvtq] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300}
		[2018-01-24T21:28:59,813][INFO ][o.e.c.s.ClusterApplierService] [lHDvvtq] new_master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300}, reason: apply cluster state (from master [master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
		[2018-01-24T21:28:59,891][INFO ][o.e.g.GatewayService     ] [lHDvvtq] recovered [0] indices into cluster_state
		[2018-01-24T21:28:59,922][INFO ][o.e.h.n.Netty4HttpServerTransport] [lHDvvtq] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
		[2018-01-24T21:28:59,922][INFO ][o.e.n.Node               ] [lHDvvtq] started
		
		当出现   starting ...   started 即启动成功
		
		
		再次启动可能会遇到的错误
		ERROR: [2] bootstrap checks failed
		[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]	
		[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		
		
		[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]	
		原因 ：无法创建本地文件问题,用户最大可创建文件数太小
		cd /etc/security
		vi limits.conf
		在最后面添加
		* soft nofile 65536
		* hard nofile 131072
		* soft nproc 2048
		* hard nproc 4096
		
		备注：* 代表Linux所有用户名称（比如 hadoop）
		需要保存、退出、重新登录才可生效。
		exit 
		su elsearch 问题1即可解决
		
		[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		
		原因：最大虚拟内存太小
		cd /etc
		vi sysctl.conf
		在最后面写入
		vm.max_map_count=655360
		保存后
		sysctl -p
		然后，重新启动elasticsearch，即可启动成功。
		
		
		
		此时如果访问 
		http://192.168.132.131:9200/  可能会502
		解决办法
		cd /usr/local/elasticsearch-6.1.2/config
		vi elasticsearch.yml
		#network.host: 192.168.0.1
		配置成 network.host: 0.0.0.0
		
		再次访问即可
		
		http://192.168.132.131:9200/
		结果如下
		{
		  "name" : "lHDvvtq",
		  "cluster_name" : "elasticsearch",
		  "cluster_uuid" : "xJOREnD4SjmFPrsDwXiD4g",
		  "version" : {
		    "number" : "6.1.2",
		    "build_hash" : "5b1fea5",
		    "build_date" : "2018-01-10T02:35:59.208Z",
		    "build_snapshot" : false,
		    "lucene_version" : "7.1.0",
		    "minimum_wire_compatibility_version" : "5.6.0",
		    "minimum_index_compatibility_version" : "5.0.0"
		  },
		  "tagline" : "You Know, for Search"
		}
		

	D:	Elasticsearch 图形界面
		安装head 插件  json 数据不友好、 使用该插件 解决了友好的界面问题
		该插件需要node 的支持请确保node已经安装这里我已经安装了node
		cd /usr/local
		wget https://github.com/mobz/elasticsearch-head/archive/master.zip
		解压
		unzip master.zip
		cd elasticsearch-head-master/
		/usr/local/node-v8.5.0/bin/npm install
		等待安装完成
		
		/usr/local/node-v8.5.0/bin/npm run start
		运行
		[root@localhost elasticsearch-head-master]# /usr/local/node-v8.5.0/bin/npm run start

		> elasticsearch-head@0.0.0 start /usr/local/elasticsearch-head-master
		> grunt server
		
		Running "connect:server" (connect) task
		Waiting forever...
		Started connect web server on http://localhost:9100
		
		服务已启动
		
		此时访问
		
		http://192.168.132.131:9200/
		即可有图形化的界面出现
		
	F:	此时虽然head插件有显示 但是 elasticsearch 和 elasticsearch-head 是连个独立的进程 无法通信。需要配置如下
		
		a:	添加配置
			/usr/local/elasticsearch-6.1.2/config
			vi elasticsearch.yml
			在最后面 务必按照如下完整的格式 true 前必须要有空格
			http.cors.enabled: true
			http.cors.allow-origin: "*"
		b:	保存退出
		
	G:	此时后台启动
		cd ..
		cd bin
		./elasticsearch -d 后台启动
	H:	开启head插件
		如果此时还没有连接成功
		需修改监head插件源码
		修改服务器监听地址:Gruntfile.js
		cd /usr/local/elasticsearch-head-master
		vi Gruntfile.js
		添加hostname: '*'
		connect: {
                        server: {
                                options: {
                                        port: 9100,
                                        base: '.',
                                        keepalive: true,
                                        hostname: '*'
                                }
                        }
                }
		
		
		修改连接地址：_site/app.js
		cd /usr/local/elasticsearch-head-master/_site
		vi app.js
		将如下的修改为你访问的客户端地址
		http://localhost:9200
		如我本机的改为
		http://192.168.132.131:9200
		改好之后
		cd /usr/local/elasticsearch-head-master
		此时在浏览器里再次访问
		以监控的ip为192.168.132.131为例
		http://192.168.132.131:9100/
		当连接后面的字体变成绿色的时候我们已经连接成功了。
	I:	
		安装配置及analysis-ik中文分词插件安装   最好是同一版本的
		wget https://github.com/medcl/elasticsearch-analysis-ik/archive/master.zip
		unzip master.zip
		安装maven
		cd elasticsearch-analysis-ik-master
		mvn clean
		出现
		[INFO] BUILD SUCCESS
		表示ok
		mvn package
		打包完成后
		cd /target/releases
		cd /usr/local/elasticsearch-6.1.2/plugins/
		在elasticsearch 的 plugins目录下穿件 analysis-ik 目录
		mkdir analysis-ik
		cd -
		cp elasticsearch-analysis-ik-6.1.1.zip /usr/local/elasticsearch-6.1.2/plugins/analysis-ik/
		cd /usr/local/elasticsearch-6.1.2/plugins/analysis-ik/
		
		unzip elasticsearch-analysis-ik-6.1.1.zip
		在ES的配置文件elasticsearch.yml中增加ik的配置
		cd /usr/local/elasticsearch-6.1.2/config
		vi elasticsearch.yml
		在最后写入
		index.analysis.analyzer.ik.type: "ik"
		重启elasticsearch服务
		[elsearch@localhost bin]$ ./elasticsearch
			[2018-01-27T00:42:52,981][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]
			org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: plugin [analysis-ik] is incompatible with version [6.1.2]; was designed for version [6.1.1]
				at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:125) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:112) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:85) ~[elasticsearch-6.1.2.jar:6.1.2]
			Caused by: java.lang.IllegalArgumentException: plugin [analysis-ik] is incompatible with version [6.1.2]; was designed for version [6.1.1]
				at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:155) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Spawner.spawnNativePluginControllers(Spawner.java:80) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:166) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:322) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:121) ~[elasticsearch-6.1.2.jar:6.1.2]
				... 6 more
			
		报如下的错误。
		最新版本的es 是6.1.2的而我用的分词插件是6.1.1的所以是没法用的。
		分词等6.1.2的分词出来再继续
		
		
		
		
		
		
		
7：logstash
	使用mysql作为数据的存储。用elasticsearch做搜索。就需要将数据同步到elasticsearch中
	A:	官网下载最新的
		wget https://artifacts.elastic.co/downloads/logstash/logstash-6.1.2.tar.gz
		cp logstash-6.1.2.tar.gz /usr/local/
		tar -zxvf logstash-6.1.2.tar.gz
		cd logstash-6.1.2/bin
		执行以下命令
		./logstash -e 'input { stdin { } } output { stdout {} }'
		输入helloword
		控制台会输出以下内容即为ok
		2018-01-25T13:24:02.112Z localhost.localdomain hellword
		
		或者执行以下命令
		./logstash -e ""
		控制台显示
		The stdin plugin is now waiting for input:
		[2018-01-25T21:28:46,683][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
		{
		          "type" => "stdin",
		    "@timestamp" => 2018-01-25T13:28:46.644Z,
		      "@version" => "1",
		       "message" => "helloword",
		          "host" => "localhost.localdomain"
		}
		即为ok
		
		
8： 安装logstash-input-jdbc插件
	附上官网文档 https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html
	logstash-input-jdbc插件是logstash 的一个插件。
	A:	首先查看是否安装gem。 如果没有安装 gem 的话 安装gem 
		yum install gem
		安装完
		gem -v
		查看版本号
	B:	cd /usr/local/logstash-6.1.2/bin
		通过自带的命令安装（较慢）
		./logstash-plugin install logstash-input-jdbc
		
		Validating logstash-input-jdbc
		Installing logstash-input-jdbc
		Installation successful
		
		安装完成
		
		wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.45.tar.gz		
		cp mysql-connector-java-5.1.45.tar.gz	/usr/local/logstash-6.1.2
		创建两个配置文件
		//@Todo
		
		cd /usr/local/logstash-6.1.2
		mdkir etc
		cd etc
		touch index.conf index.sql
		vi index.conf（索引配置文件）
		
		input {
		    stdin {
		    }
		    jdbc {
		      # mysql 数据库链接,test为数据库名
		      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
		      # 用户名和密码
		      jdbc_user => "root"
		      jdbc_password => "*******"
		      # 驱动
		      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
		      # 驱动类名
		      jdbc_driver_class => "com.mysql.jdbc.Driver"
		      jdbc_paging_enabled => "true"
		      # 分页数
		      jdbc_page_size => "50000"
		      # 执行的sql 文件路径+名称 也可直接用sql
		      #statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
		      # 可用sql
		      statement => "select * from user"
		      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
		      schedule => "* * * * *"
		      # 索引类型 一般以数据库中的表命名
		      type => "user"
		    }
		}
		
		filter {
		    json {
		        source => "message"
		        remove_field => ["message"]
		    }
		}
		
		
		output {
			 elasticsearch {
		        	hosts => ["192.168.132.131:9200"]
		        	#user => "elastic"   //如果这里使用x-pack作为安全管理，要配置user和password；
        			#password => "changeme"
		        	# 索引
		        	index => "test"
					#指定索引类型
		        	document_type => "user"
		        	# 自增ID 需要关联的数据库中有有一个id字段，对应索引的id号
		        	document_id => "%{id}"
		        	
                    #以下是创建模板暂时不需要
                    #manage_template => true #注意默认为true,一定不能设置为false
                    #template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
                    #template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
　　                                 #template => "/home/apps/logstash/template/logstash.json" #映射配置文件的位置（此处可能会报错 后面再解决）
		   	   }
		
			 stdout {
				#以JSON格式输出
		  		codec => json_lines
			}
		}
		
		:wq
		保存后
		
		cd /usr/local/logstash-6.1.2
		./bin/logstash -f ./etc/index.conf（指定配置文件启动）
		启动需要点时间
		[2018-01-27T16:16:05,389][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
		The stdin plugin is now waiting for input:
		[2018-01-27T16:16:05,843][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
		 出现以上信息意味着logstash 启动成功
		此时往user表中插入一条数据
		INSERT INTO user (`name`,`age`) value ('张三', 45);
		过几秒
		es中也便有了这条数据
		
		测试sql 
		INSERT INTO user (`name`,`age`,`update_time`) value ('张三', 45, unix_timestamp());
		
		注意
		当插入第一条数据时
		logstash控制台输出一条数据
		{"@version":"1","@timestamp":"2018-01-27T08:20:00.402Z","name":"张三","id":32,"type":"user","age":45}
		当插入第二条数据时
		logstash控制台输出两条数据
		{"@version":"1","@timestamp":"2018-01-27T08:21:00.323Z","name":"张三","id":32,"type":"user","age":45}
		{"@version":"1","@timestamp":"2018-01-27T08:21:00.323Z","name":"张三","id":33,"type":"user","age":45}	
		也就是一味着我们上面配置的是全量的同步而非增量的。
		以上是全部的数据是非增量添加的。
		意味 每次定时跑的时候会权标扫描一次 然后 更新到es中
		（注意 启动同步时 不会立刻去做一次数据的同步）
		
		全量索引的用处是当你的表中已经有n条数据的时候 第一同步的时候可以使用全量（注意预留足够的创建索引所需的时间 和 磁盘空间）
	
	C:
		以下我们将配置增量添加的
		首先 获取下系统时间戳
		date +%s
		cd /usr/local/logstash-6.1.2/etc
		vi index.sql
		SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= :sql_last_value
		（sql_last_value不是sql 的写法）
				
		修改index.conf
		
		# 执行的sql 文件路径+名称 也可直接用sql
        statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
        # 可用sql
        #statement => "select * from user"
        
       	再次启动 logstash
       	SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= '2018-01-27 09:15:00'
		执行计划中的sql 语句是如上的。少个8个小时        
        
                新的sql执行语句
        SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= DATE_ADD(:sql_last_value,INTERVAL 8 HOUR)
		    
        
                即可
         
                再次启动logstash       
        发现依然 查不到数据
        原来sql 写错了改成如下
        SELECT id,name,age,update_time FROM user WHERE update_time >= UNIX_TIMESTAMP(date_add(:sql_last_value,interval 8 hour))
	经过这样发现只有新增的数据才会 被更新。（需要更新update_time）的时间
	
	目前我们已经实现增量更新了。
	（针对删除操作 稍后做处理）		
			
			
			
			
			
	D:	配置多模板支持
		input {
			    stdin {
			    }
			    jdbc {
			      # mysql 数据库链接,test为数据库名
			      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
			      # 用户名和密码
			      jdbc_user => "root"
			      jdbc_password => "nihao123"
			      # 驱动
			      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
			      # 驱动类名
			      jdbc_driver_class => "com.mysql.jdbc.Driver"
			      jdbc_paging_enabled => "true"
			      # 分页数
			      jdbc_page_size => "50000"
			      # 执行的sql 文件路径+名称 也可直接用sql
			      statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
			      # 可用sql
			      #statement => "select * from user"
			      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
			      schedule => "* * * * *"
			      type => "user"
			    }
	                    jdbc {
	                      # mysql 数据库链接,test为数据库名
	                      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
	                      # 用户名和密码
	                      jdbc_user => "root"
	                      jdbc_password => "nihao123"
	                      # 驱动
	                      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
	                      # 驱动类名
	                      jdbc_driver_class => "com.mysql.jdbc.Driver"
	                      jdbc_paging_enabled => "true"
	                      # 分页数
	                      jdbc_page_size => "50000"
	                      # 执行的sql 文件路径+名称 也可直接用sql
	                      statement_filepath => "/usr/local/logstash-6.1.2/etc/news.sql"
	                      # 可用sql
	                      #statement => "select * from user"
	                      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
	                      schedule => "* * * * *"
	                      type => "news"
	                    }
	
			}
			
			filter {
			    json {
			        source => "message"
			        remove_field => ["message"]
			    }
			}
			
			
			output {
	
				if [type] == "user"{
					 elasticsearch {
			        		hosts => ["192.168.132.131:9200"]
						#指定索引
			        		index => "test"
						#指定索引类型
						document_type => "user"
			        		document_id => "%{id}"
						#以下是创建模板暂时不需要
						#manage_template => true #注意默认为true,一定不能设置为false
	        				#template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
	        				#template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
			   	   	}
				}
	
				if [type] == "news"{
					elasticsearch {
	                	                hosts => ["192.168.132.131:9200"]
	                        	        #指定索引
	                                	index => "news"
	        	                        #指定索引类型
	                	                document_type => "news"
	                        	        document_id => "%{id}"
	                                	#以下是创建模板暂时不需要
	       		                        #manage_template => true #注意默认为true,一定不能设置为false
	                        	        #template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
	                                	#template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
	                           	}
				}
				 stdout {
					#以JSON格式输出
			  		codec => json_lines
				}
			}
			配置多个jdbc指定不同的type即可。具体见上面的配置
	
			
			
			
			
9：	elasticsearch-php 插件支持
	
	A:	安装elasticsearch-php
		该插件作者建议composer安装
		安装composer
		建议 cd 到 /usr/local/php 我这里没有
		
		curl -s http://getcomposer.org/installer | php
	B:	在项目中穿件	composer.json文件
		vi composer.json
		写入如下数据
		{
	        "require": {
	            "elasticsearch/elasticsearch": "~6.0"
	        }
	    }
	    
		cd 到项目根目录
		因为我的是所以执行下面的命令
		php /root/composer.phar install
		这可能需要点时间
		安装完成后
		目录下
		composer.lock文件 vendor 目录
		
	
	
		