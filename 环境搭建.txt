1：安装jdk
	A:	linux 下wget http://download.oracle.com/otn-pub/java/jdk/8u162-b12/0da788060d494f5095bf8624735fa2f1/jdk-8u162-linux-x64.tar.gz  
	B:	makdir /usr/local/java  
	C:	mv jdk-8u162-linux-x64.tar.gz /usr/local/java  
	D:	tar -zxvf jdk-8u162-linux-x64.tar.gz  
	E:	vi /etc/profile  
	F: 	在文件的最后写入  
		export JAVA_HOME=/usr/local/java/jdk1.8.0_162  
		xport JRE_HOME=/usr/local/java/jdk1.8.0_162/jre  
		export PATH=$PATH:/usr/local/java/jdk1.8.0_162/bin  
		export CLASSPATH=./:/usr/local/java/jdk1.8.0_162/lib:/usr/local/java/jdk1.8.0_162/jre/lib  
		
	G:	source /etc/profile  
	
	H:	java -version显示如下信息即可  
		java version "1.8.0_162"  
		Java(TM) SE Runtime Environment (build 1.8.0_162-b12)  
		Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)  
		jdk至此安装完毕  



5：	安装node 
		wget https://nodejs.org/dist/v8.5.0/node-v8.5.0-linux-x64.tar.gz
		解压
		mv node-v8.5.0/ /usr/local
		cd node-v8.5.0
		ln /usr/local/node-v8.5.0/bin/node /usr/sbin/ 设置软连接

6：elasticsearch安装
		wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.1.2.tar.gz
		mv elasticsearch-6.1.2.tar.gz /usr/local/
		tar -zxvf elasticsearch-6.1.2.tar.gz
		cd elasticsearch-6.1.2
		cd bin
		执行启动可能会报错
		./elasticsearch
		报错如下
		
		[2018-01-24T21:07:17,532][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]
		org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root
			at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:125) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:112) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
			at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:85) ~[elasticsearch-6.1.2.jar:6.1.2]
		Caused by: java.lang.RuntimeException: can not run elasticsearch as root
			at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:104) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:171) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:322) ~[elasticsearch-6.1.2.jar:6.1.2]
			at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:121) ~[elasticsearch-6.1.2.jar:6.1.2]
			... 6 more
			
			
		注意这个报错  org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as root
		elasticsearch 不能以root 用户运行。也是为了安全考虑
		
		因为安全问题elasticsearch 不让用root用户直接运行，所以要创建新用户
	
		建议创建一个单独的用户用来运行ElasticSearch
		
		
	A:	创建elsearch用户组及elsearch用户
		groupadd elsearch
		useradd elsearch -g elsearch -p elasticsearch
	
	B:	更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearch
		cd /usr/local
		chown -R elsearch:elsearch  elasticsearch-6.1.2
		
	C:	切换到elsearch用户再启动
		su elsearch
		cd /elasticsearch-6.1.2/bin
		启动
		./elasticsearch
		
		
		[2018-01-24T21:28:55,847][INFO ][o.e.n.Node               ] [lHDvvtq] starting ...
		[2018-01-24T21:28:56,311][INFO ][o.e.t.TransportService   ] [lHDvvtq] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
		[2018-01-24T21:28:56,496][WARN ][o.e.b.BootstrapChecks    ] [lHDvvtq] max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]
		[2018-01-24T21:28:56,496][WARN ][o.e.b.BootstrapChecks    ] [lHDvvtq] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		[2018-01-24T21:28:59,805][INFO ][o.e.c.s.MasterService    ] [lHDvvtq] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300}
		[2018-01-24T21:28:59,813][INFO ][o.e.c.s.ClusterApplierService] [lHDvvtq] new_master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300}, reason: apply cluster state (from master [master {lHDvvtq}{lHDvvtqFQsGeSSWPxooS5w}{McqGNmL8RRGuw5xLqlIDxg}{127.0.0.1}{127.0.0.1:9300} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
		[2018-01-24T21:28:59,891][INFO ][o.e.g.GatewayService     ] [lHDvvtq] recovered [0] indices into cluster_state
		[2018-01-24T21:28:59,922][INFO ][o.e.h.n.Netty4HttpServerTransport] [lHDvvtq] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
		[2018-01-24T21:28:59,922][INFO ][o.e.n.Node               ] [lHDvvtq] started
		
		当出现   starting ...   started 即启动成功
		
		
		再次启动可能会遇到的错误
		ERROR: [2] bootstrap checks failed
		[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]	
		[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		
		
		[1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536]	
		原因 ：无法创建本地文件问题,用户最大可创建文件数太小
		cd /etc/security
		vi limits.conf
		在最后面添加
		* soft nofile 65536
		* hard nofile 131072
		* soft nproc 2048
		* hard nproc 4096
		
		备注：* 代表Linux所有用户名称（比如 hadoop）
		需要保存、退出、重新登录才可生效。
		exit 
		su elsearch 问题1即可解决
		
		[2]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
		
		原因：最大虚拟内存太小
		cd /etc
		vi sysctl.conf
		在最后面写入
		vm.max_map_count=655360
		保存后
		sysctl -p
		然后，重新启动elasticsearch，即可启动成功。
		
		
		
		此时如果访问 
		http://192.168.132.131:9200/  可能会502
		解决办法
		cd /usr/local/elasticsearch-6.1.2/config
		vi elasticsearch.yml
		#network.host: 192.168.0.1
		配置成 network.host: 0.0.0.0
		
		再次访问即可
		
		http://192.168.132.131:9200/
		结果如下
		{
		  "name" : "lHDvvtq",
		  "cluster_name" : "elasticsearch",
		  "cluster_uuid" : "xJOREnD4SjmFPrsDwXiD4g",
		  "version" : {
		    "number" : "6.1.2",
		    "build_hash" : "5b1fea5",
		    "build_date" : "2018-01-10T02:35:59.208Z",
		    "build_snapshot" : false,
		    "lucene_version" : "7.1.0",
		    "minimum_wire_compatibility_version" : "5.6.0",
		    "minimum_index_compatibility_version" : "5.0.0"
		  },
		  "tagline" : "You Know, for Search"
		}
		

	D:	Elasticsearch 图形界面
		安装head 插件  json 数据不友好、 使用该插件 解决了友好的界面问题
		该插件需要node 的支持请确保node已经安装这里我已经安装了node
		cd /usr/local
		wget https://github.com/mobz/elasticsearch-head/archive/master.zip
		解压
		unzip master.zip
		cd elasticsearch-head-master/
		/usr/local/node-v8.5.0/bin/npm install
		等待安装完成
		
		/usr/local/node-v8.5.0/bin/npm run start
		运行
		[root@localhost elasticsearch-head-master]# /usr/local/node-v8.5.0/bin/npm run start

		> elasticsearch-head@0.0.0 start /usr/local/elasticsearch-head-master
		> grunt server
		
		Running "connect:server" (connect) task
		Waiting forever...
		Started connect web server on http://localhost:9100
		
		服务已启动
		
		此时访问
		
		http://192.168.132.131:9200/
		即可有图形化的界面出现
		
	F:	此时虽然head插件有显示 但是 elasticsearch 和 elasticsearch-head 是连个独立的进程 无法通信。需要配置如下
		
		a:	添加配置
			/usr/local/elasticsearch-6.1.2/config
			vi elasticsearch.yml
			在最后面 务必按照如下完整的格式 true 前必须要有空格
			http.cors.enabled: true
			http.cors.allow-origin: "*"
		b:	保存退出
		
	G:	此时后台启动
		cd ..
		cd bin
		./elasticsearch -d 后台启动
	H:	开启head插件
		如果此时还没有连接成功
		需修改监head插件源码
		修改服务器监听地址:Gruntfile.js
		cd /usr/local/elasticsearch-head-master
		vi Gruntfile.js
		添加hostname: '*'
		connect: {
                        server: {
                                options: {
                                        port: 9100,
                                        base: '.',
                                        keepalive: true,
                                        hostname: '*'
                                }
                        }
                }
		
		
		修改连接地址：_site/app.js
		cd /usr/local/elasticsearch-head-master/_site
		vi app.js
		将如下的修改为你访问的客户端地址
		http://localhost:9200
		如我本机的改为
		http://192.168.132.131:9200
		改好之后
		cd /usr/local/elasticsearch-head-master
		此时在浏览器里再次访问
		以监控的ip为192.168.132.131为例
		http://192.168.132.131:9100/
		当连接后面的字体变成绿色的时候我们已经连接成功了。
	I:	
		安装配置及analysis-ik中文分词插件安装   最好是同一版本的
		wget https://github.com/medcl/elasticsearch-analysis-ik/archive/master.zip
		unzip master.zip
		安装maven
		cd elasticsearch-analysis-ik-master
		mvn clean
		出现
		[INFO] BUILD SUCCESS
		表示ok
		mvn package
		打包完成后
		cd /target/releases
		cd /usr/local/elasticsearch-6.1.2/plugins/
		在elasticsearch 的 plugins目录下穿件 analysis-ik 目录
		mkdir analysis-ik
		cd -
		cp elasticsearch-analysis-ik-6.1.1.zip /usr/local/elasticsearch-6.1.2/plugins/analysis-ik/
		cd /usr/local/elasticsearch-6.1.2/plugins/analysis-ik/
		
		unzip elasticsearch-analysis-ik-6.1.1.zip
		在ES的配置文件elasticsearch.yml中增加ik的配置
		cd /usr/local/elasticsearch-6.1.2/config
		vi elasticsearch.yml
		在最后写入
		index.analysis.analyzer.ik.type: "ik"
		重启elasticsearch服务
		[elsearch@localhost bin]$ ./elasticsearch
			[2018-01-27T00:42:52,981][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main]
			org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: plugin [analysis-ik] is incompatible with version [6.1.2]; was designed for version [6.1.1]
				at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:125) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:112) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:124) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
				at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-cli-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:85) ~[elasticsearch-6.1.2.jar:6.1.2]
			Caused by: java.lang.IllegalArgumentException: plugin [analysis-ik] is incompatible with version [6.1.2]; was designed for version [6.1.1]
				at org.elasticsearch.plugins.PluginInfo.readFromProperties(PluginInfo.java:155) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Spawner.spawnNativePluginControllers(Spawner.java:80) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:166) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:322) ~[elasticsearch-6.1.2.jar:6.1.2]
				at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:121) ~[elasticsearch-6.1.2.jar:6.1.2]
				... 6 more
			
		报如下的错误。
		最新版本的es 是6.1.2的而我用的分词插件是6.1.1的所以是没法用的。
		分词等6.1.2的分词出来再继续
		
		
		换一种方式安装
		https://github.com/medcl/elasticsearch-analysis-ik/releases 一定要以这儿的为准
		
		cd /usr/local/elasticsearch-6.1.2
		
		./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.1.2/elasticsearch-analysis-ik-6.1.2.zip
		
		[elsearch@localhost elasticsearch-6.1.2]$ ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.1.2/elasticsearch-analysis-ik-6.1.2.zip
		-> Downloading https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.1.2/elasticsearch-analysis-ik-6.1.2.zip
		[=================================================] 100%   
		-> Installed analysis-ik
		以上表示安装成功
		
		并且在conf会多出来一个analysis-ik目录
		[elsearch@localhost config]$ pwd
		/usr/local/elasticsearch-6.1.2/config
		[elsearch@localhost config]$ ls
		analysis-ik  elasticsearch.yml  jvm.options  log4j2.properties
		[elsearch@localhost config]$
		
		
		./bin/elasticsearch-plugin install安装成功的话下面的配置需干掉
		index.analysis.analyzer.ik.type: "ik"
		
		
7：logstash
	使用mysql作为数据的存储。用elasticsearch做搜索。就需要将数据同步到elasticsearch中
	A:	官网下载最新的
		wget https://artifacts.elastic.co/downloads/logstash/logstash-6.1.2.tar.gz
		cp logstash-6.1.2.tar.gz /usr/local/
		tar -zxvf logstash-6.1.2.tar.gz
		cd logstash-6.1.2/bin
		执行以下命令
		./logstash -e 'input { stdin { } } output { stdout {} }'
		输入helloword
		控制台会输出以下内容即为ok
		2018-01-25T13:24:02.112Z localhost.localdomain hellword
		
		或者执行以下命令
		./logstash -e ""
		控制台显示
		The stdin plugin is now waiting for input:
		[2018-01-25T21:28:46,683][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
		{
		          "type" => "stdin",
		    "@timestamp" => 2018-01-25T13:28:46.644Z,
		      "@version" => "1",
		       "message" => "helloword",
		          "host" => "localhost.localdomain"
		}
		即为ok
		
		
8： 安装logstash-input-jdbc插件
	附上官网文档 https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html
	logstash-input-jdbc插件是logstash 的一个插件。
	A:	首先查看是否安装gem。 如果没有安装 gem 的话 安装gem 
		yum install gem
		安装完
		gem -v
		查看版本号
	B:	cd /usr/local/logstash-6.1.2/bin
		通过自带的命令安装（较慢）
		./logstash-plugin install logstash-input-jdbc
		
		Validating logstash-input-jdbc
		Installing logstash-input-jdbc
		Installation successful
		
		安装完成
		
		wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.45.tar.gz		
		cp mysql-connector-java-5.1.45.tar.gz	/usr/local/logstash-6.1.2
		创建两个配置文件
		//@Todo
		
		cd /usr/local/logstash-6.1.2
		mdkir etc
		cd etc
		touch index.conf index.sql
		vi index.conf（索引配置文件）
		
		input {
		    stdin {
		    }
		    jdbc {
		      # mysql 数据库链接,test为数据库名
		      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
		      # 用户名和密码
		      jdbc_user => "root"
		      jdbc_password => "*******"
		      # 驱动
		      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
		      # 驱动类名
		      jdbc_driver_class => "com.mysql.jdbc.Driver"
		      jdbc_paging_enabled => "true"
		      # 分页数
		      jdbc_page_size => "50000"
		      # 执行的sql 文件路径+名称 也可直接用sql
		      #statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
		      # 可用sql
		      statement => "select * from user"
		      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
		      schedule => "* * * * *"
		      # 索引类型 一般以数据库中的表命名
		      type => "user"
		    }
		}
		
		filter {
		    json {
		        source => "message"
		        remove_field => ["message"]
		    }
		}
		
		
		output {
			 elasticsearch {
		        	hosts => ["192.168.132.131:9200"]
		        	#user => "elastic"   //如果这里使用x-pack作为安全管理，要配置user和password；
        			#password => "changeme"
		        	# 索引
		        	index => "test"
					#指定索引类型
		        	document_type => "user"
		        	# 自增ID 需要关联的数据库中有有一个id字段，对应索引的id号
		        	document_id => "%{id}"
		        	
                    #以下是创建模板暂时不需要
                    #manage_template => true #注意默认为true,一定不能设置为false
                    #template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
                    #template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
　　                                 #template => "/home/apps/logstash/template/logstash.json" #映射配置文件的位置（此处可能会报错 后面再解决）
		   	   }
		
			 stdout {
				#以JSON格式输出
		  		codec => json_lines
			}
		}
		
		:wq
		保存后
		
		cd /usr/local/logstash-6.1.2
		./bin/logstash -f ./etc/index.conf（指定配置文件启动）
		启动需要点时间
		[2018-01-27T16:16:05,389][INFO ][logstash.pipeline        ] Pipeline started {"pipeline.id"=>"main"}
		The stdin plugin is now waiting for input:
		[2018-01-27T16:16:05,843][INFO ][logstash.agent           ] Pipelines running {:count=>1, :pipelines=>["main"]}
		 出现以上信息意味着logstash 启动成功
		此时往user表中插入一条数据
		INSERT INTO user (`name`,`age`) value ('张三', 45);
		过几秒
		es中也便有了这条数据
		
		测试sql 
		INSERT INTO user (`name`,`age`,`update_time`) value ('张三', 45, unix_timestamp());
		
		注意
		当插入第一条数据时
		logstash控制台输出一条数据
		{"@version":"1","@timestamp":"2018-01-27T08:20:00.402Z","name":"张三","id":32,"type":"user","age":45}
		当插入第二条数据时
		logstash控制台输出两条数据
		{"@version":"1","@timestamp":"2018-01-27T08:21:00.323Z","name":"张三","id":32,"type":"user","age":45}
		{"@version":"1","@timestamp":"2018-01-27T08:21:00.323Z","name":"张三","id":33,"type":"user","age":45}	
		也就是一味着我们上面配置的是全量的同步而非增量的。
		以上是全部的数据是非增量添加的。
		意味 每次定时跑的时候会权标扫描一次 然后 更新到es中
		（注意 启动同步时 不会立刻去做一次数据的同步）
		
		全量索引的用处是当你的表中已经有n条数据的时候 第一同步的时候可以使用全量（注意预留足够的创建索引所需的时间 和 磁盘空间）
	
	C:
		以下我们将配置增量添加的
		首先 获取下系统时间戳
		date +%s
		cd /usr/local/logstash-6.1.2/etc
		vi index.sql
		SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= :sql_last_value
		（sql_last_value不是sql 的写法）
				
		修改index.conf
		
		# 执行的sql 文件路径+名称 也可直接用sql
        statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
        # 可用sql
        #statement => "select * from user"
        
       	再次启动 logstash
       	SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= '2018-01-27 09:15:00'
		执行计划中的sql 语句是如上的。少个8个小时        
        
                新的sql执行语句
        SELECT
		    id,
		    name,
		    age,
		    update_time
		FROM
		    user
		WHERE
		    update_time >= DATE_ADD(:sql_last_value,INTERVAL 8 HOUR)
		    
        
                即可
         
                再次启动logstash       
        发现依然 查不到数据
        原来sql 写错了改成如下
        SELECT id,name,age,update_time FROM user WHERE update_time >= UNIX_TIMESTAMP(date_add(:sql_last_value,interval 8 hour))
	经过这样发现只有新增的数据才会 被更新。（需要更新update_time）的时间
	
	目前我们已经实现增量更新了。
	（针对删除操作 稍后做处理）		
			
			
			
			
			
	D:	配置多模板支持
		input {
			    stdin {
			    }
			    jdbc {
			      # mysql 数据库链接,test为数据库名
			      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
			      # 用户名和密码
			      jdbc_user => "root"
			      jdbc_password => "nihao123"
			      # 驱动
			      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
			      # 驱动类名
			      jdbc_driver_class => "com.mysql.jdbc.Driver"
			      jdbc_paging_enabled => "true"
			      # 分页数
			      jdbc_page_size => "50000"
			      # 执行的sql 文件路径+名称 也可直接用sql
			      statement_filepath => "/usr/local/logstash-6.1.2/etc/index.sql"
			      # 可用sql
			      #statement => "select * from user"
			      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
			      schedule => "* * * * *"
			      type => "user"
			    }
	                    jdbc {
	                      # mysql 数据库链接,test为数据库名
	                      jdbc_connection_string => "jdbc:mysql://192.168.132.131:3306/test?useSSL=false&useUnicode=true&characterEncoding=UTF-8"
	                      # 用户名和密码
	                      jdbc_user => "root"
	                      jdbc_password => "nihao123"
	                      # 驱动
	                      jdbc_driver_library => "/usr/local/logstash-6.1.2/mysql-connector-java-5.1.45-bin.jar"
	                      # 驱动类名
	                      jdbc_driver_class => "com.mysql.jdbc.Driver"
	                      jdbc_paging_enabled => "true"
	                      # 分页数
	                      jdbc_page_size => "50000"
	                      # 执行的sql 文件路径+名称 也可直接用sql
	                      statement_filepath => "/usr/local/logstash-6.1.2/etc/news.sql"
	                      # 可用sql
	                      #statement => "select * from user"
	                      #  设置监听间隔  各字段含义（由左至右）分、时、天、月、年，全部为*默认含义为每分钟都更新
	                      schedule => "* * * * *"
	                      type => "news"
	                    }
	
			}
			
			filter {
			    json {
			        source => "message"
			        remove_field => ["message"]
			    }
			}
			
			
			output {
	
				if [type] == "user"{
					 elasticsearch {
			        		hosts => ["192.168.132.131:9200"]
						#指定索引
			        		index => "test"
						#指定索引类型
						document_type => "user"
			        		document_id => "%{id}"
						#以下是创建模板暂时不需要
						#manage_template => true #注意默认为true,一定不能设置为false
	        				#template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
	        				#template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
			   	   	}
				}
	
				if [type] == "news"{
					elasticsearch {
	                	                hosts => ["192.168.132.131:9200"]
	                        	        #指定索引
	                                	index => "news"
	        	                        #指定索引类型
	                	                document_type => "news"
	                        	        document_id => "%{id}"
	                                	#以下是创建模板暂时不需要
	       		                        #manage_template => true #注意默认为true,一定不能设置为false
	                        	        #template_overwrite => true #如果设置为true，模板名字一样的时候，新的模板会覆盖旧的模板
	                                	#template_name => "myLogstash" #注意这个名字是用来查找映射配置的，尽量设置成全局唯一的
	                           	}
				}
				 stdout {
					#以JSON格式输出
			  		codec => json_lines
				}
			}
			配置多个jdbc指定不同的type即可。具体见上面的配置
	
			
			
			
			
9：	elasticsearch-php 插件支持
	
	A:	安装elasticsearch-php
		该插件作者建议composer安装
		安装composer
		建议 cd 到 /usr/local/php 我这里没有
		
		curl -s http://getcomposer.org/installer | php
	B:	在项目中穿件	composer.json文件
		vi composer.json
		写入如下数据
		{
	        "require": {
	            "elasticsearch/elasticsearch": "~6.0"
	        }
	    }
	    
		cd 到项目根目录
		因为我的是所以执行下面的命令
		php /root/composer.phar install
		这可能需要点时间
		安装完成后
		目录下
		composer.lock文件 vendor 目录
		
	
	
		